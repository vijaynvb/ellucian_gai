{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZDsOC8WZx24"
      },
      "source": [
        "# **Retrival**\n",
        "\n",
        "In LangChain, retrieval refers to the process of accessing and fetching relevant pieces of information from a collection of documents or data sources based on a query. This involves using techniques like similarity search and embedding-based methods to find and return the most pertinent documents or text segments that match the query's context and content."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eyhmxkE1YbWo"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain_aws pypdf tiktoken chromadb lark"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 847
        },
        "id": "I2gfpVmPO3K6",
        "outputId": "a7380db9-f1e6-44e3-8dd0-932d43c3f60a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: numpy 1.26.4\n",
            "Uninstalling numpy-1.26.4:\n",
            "  Would remove:\n",
            "    /usr/local/bin/f2py\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy-1.26.4.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libgfortran-040039e1.so.5.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libopenblas64_p-r0-0cf96a72.3.23.dev.so\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy.libs/libquadmath-96973f99.so.0.0.0\n",
            "    /usr/local/lib/python3.11/dist-packages/numpy/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled numpy-1.26.4\n",
            "Found existing installation: pandas 2.2.2\n",
            "Uninstalling pandas-2.2.2:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.11/dist-packages/pandas-2.2.2.dist-info/*\n",
            "    /usr/local/lib/python3.11/dist-packages/pandas/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled pandas-2.2.2\n",
            "Collecting numpy==1.26.4\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas\n",
            "  Downloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (91 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.2/91.2 kB\u001b[0m \u001b[31m175.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m313.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.3.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m276.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, pandas\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.3.0 which is incompatible.\n",
            "cudf-cu12 25.2.1 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "dask-cudf-cu12 25.2.2 requires pandas<2.2.4dev0,>=2.0, but you have pandas 2.3.0 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4 pandas-2.3.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "2946ef54792b4f7a95241b372112af8b",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip uninstall -y numpy pandas\n",
        "!pip install --no-cache-dir numpy==1.26.4 pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "gmhrM0gQohMS"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = userdata.get('AWS_DEFAULT_REGION')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yD-yLJRYYkgW"
      },
      "source": [
        "# **Vectorstore retrieval**\n",
        "\n",
        "Vectorstore retrieval is a technique that involves storing and retrieving data using vector representations of text. It enables efficient similarity searches by converting text into high-dimensional vectors and then finding the closest vectors in the database. This method is particularly useful for applications requiring fast and accurate information retrieval based on semantic similarity.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "uDKCuVkvbmFZ"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"/content/content/MachineLearning-Lecture01.pdf\"),\n",
        "    PyPDFLoader(\"/content/content/MachineLearning-Lecture02.pdf\"),\n",
        "    PyPDFLoader(\"/content/content/MachineLearning-Lecture03.pdf\")\n",
        "\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZdCG2EYbnD6",
        "outputId": "568df721-5763-4821-f191-0366501213a9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ojzmOu7OoyNm"
      },
      "outputs": [],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory = 'docs/chroma/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ja6dCyY1pEGQ"
      },
      "outputs": [],
      "source": [
        "from langchain_aws import BedrockEmbeddings\n",
        "\n",
        "embedding = BedrockEmbeddings(\n",
        "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
        ")\n",
        "\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H22zqjeWpYef",
        "outputId": "2aa2b80d-27dd-4376-ec1b-2d114324044e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "302"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vectordb._collection.count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "I-SK9rxSpc2V"
      },
      "outputs": [],
      "source": [
        "texts = [\n",
        "    \"\"\"The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).\"\"\",\n",
        "    \"\"\"A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.\"\"\",\n",
        "    \"\"\"A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.\"\"\",\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ALEQTlhCpgV_"
      },
      "outputs": [],
      "source": [
        "smalldb = Chroma.from_texts(texts, embedding=embedding)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "5M6a4hE3pgqO"
      },
      "outputs": [],
      "source": [
        "question = \"Tell me about all-white mushrooms with large fruiting bodies\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVd3L-5sYpln"
      },
      "source": [
        "# **Similarity Search**\n",
        "\n",
        "Similarity search is a method used to find items in a database that are most similar to a given query item based on certain criteria. It involves comparing vector representations of items and retrieving those with the smallest distance or highest similarity score. This approach is commonly used in applications like document retrieval, image matching, and recommendation systems.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CAydVLibpgu1",
        "outputId": "b3170556-bcef-4492-fdf8-670a414c2018"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
              " Document(metadata={}, page_content='The Amanita phalloides has a large and imposing epigeous (aboveground) fruiting body (basidiocarp).')]"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smalldb.similarity_search(question, k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gztlWTUsp3Iz",
        "outputId": "5af79a0e-c9a9-4e61-f4ad-f1cc7780f6f5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[Document(metadata={}, page_content='A mushroom with a large fruiting body is the Amanita phalloides. Some varieties are all-white.'),\n",
              " Document(metadata={}, page_content='A. phalloides, a.k.a Death Cap, is one of the most poisonous of all known mushrooms.')]"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "smalldb.max_marginal_relevance_search(question,k=2, fetch_k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw97_yj2aili"
      },
      "source": [
        "## Addressing Diversity: Maximum marginal relevance\n",
        "\n",
        "Last class we introduced one problem: how to enforce diversity in the search results.\n",
        "\n",
        "`Maximum marginal relevance` strives to achieve both relevance to the query *and diversity* among the results.\n",
        "\n",
        "Maximum Marginal Relevance (MMR) is a technique used in information retrieval to enhance the diversity of search results. It aims to select documents that are not only relevant to a query but also diverse from each other. This diversity helps provide a broader perspective or coverage of the topic being queried.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aIecO_wsZui6"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "docs_ss = vectordb.similarity_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "nlK1SP4aaqcG",
        "outputId": "4e71aa3d-9267-4aeb-cdc6-c6ee412903e6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'into his office and he said, \"Oh, professor, professor, thank you so much for your \\nmachine learning'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_ss[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "j-9TE7-_asd1",
        "outputId": "89938e10-7ffd-47f9-9bf4-a29b0e19007a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'into his office and he said, \"Oh, professor, professor, thank you so much for your \\nmachine learning'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_ss[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O4C--BrRcnJJ"
      },
      "source": [
        "Note the difference in results with `MMR`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "pFsLht7Ucmbx"
      },
      "outputs": [],
      "source": [
        "docs_mmr = vectordb.max_marginal_relevance_search(question,k=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "vtbK71DucqzB",
        "outputId": "0f15e1b3-6c2f-4699-fe3e-8ddbd4b63ce6"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'into his office and he said, \"Oh, professor, professor, thank you so much for your \\nmachine learning'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_mmr[0].page_content[:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "4Cmv6V5ucr_1",
        "outputId": "e380fe2d-f4e1-460e-ba02-0250cd584b27"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people c'"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs_mmr[1].page_content[:100]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bIQyJjqcyGo"
      },
      "source": [
        "## **Addressing Specificity: working with metadata**\n",
        "\n",
        "In last lecture, we showed that a question about the third lecture can include results from other lectures as well.\n",
        "\n",
        "To address this, many vectorstores support operations on `metadata`.\n",
        "\n",
        "`metadata` provides context for each embedded chunk.\n",
        "\n",
        "Metadata filtering refers to the process of selectively retrieving or excluding data based on predefined metadata attributes or criteria. In the context of information retrieval systems like LangChain, metadata filtering allows users to narrow down search results by specifying metadata tags or attributes associated with documents or data chunks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "OyCYTYboctXP"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about regression in the third lecture?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "jnW9VfKJc2Uz"
      },
      "outputs": [],
      "source": [
        "docs = vectordb.similarity_search(\n",
        "    question,\n",
        "    k=3,\n",
        "    filter={\"source\":\"docs/cs229_lectures/MachineLearning-Lecture03.pdf\"}\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "HMESrO2Zc3jk"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    d.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZpSertVc_mi"
      },
      "source": [
        "## **Addressing Specificity: working with metadata using self-query retriever**\n",
        "\n",
        "But we have an interesting challenge: we often want to infer the metadata from the query itself.\n",
        "\n",
        "To address this, we can use `SelfQueryRetriever`, which uses an LLM to extract:\n",
        "\n",
        "1. The `query` string to use for vector search\n",
        "2. A metadata filter to pass in as well\n",
        "\n",
        "Most vector databases support metadata filters, so this doesn't require any new databases or indexes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "daIJI8cSc48Z"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain_aws import BedrockLLM\n",
        "from langchain.chains.query_constructor.base import AttributeInfo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "1mgSnmYidDWN"
      },
      "outputs": [],
      "source": [
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"source\",\n",
        "        description=\"The lecture the chunk is from, should be one of `docs/cs229_lectures/MachineLearning-Lecture01.pdf`, `docs/cs229_lectures/MachineLearning-Lecture02.pdf`, or `docs/cs229_lectures/MachineLearning-Lecture03.pdf`\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"page\",\n",
        "        description=\"The page from the lecture\",\n",
        "        type=\"integer\",\n",
        "    ),\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "NUov2iPZdF_J"
      },
      "outputs": [],
      "source": [
        "document_content_description = \"Lecture notes\"\n",
        "llm = BedrockLLM(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "retriever = SelfQueryRetriever.from_llm(\n",
        "    llm,\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    verbose=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UXHu75E_dLRx"
      },
      "outputs": [],
      "source": [
        "question = \"what did they say about regression in the third lecture?\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBlr6jzNda58"
      },
      "source": [
        "**You will receive a warning** about predict_and_parse being deprecated the first time you executing the next line. This can be safely ignored."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Sdl8kDRdaVf",
        "outputId": "22e3a7e5-1317-4e6d-e458-96da9716c70a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipython-input-25-10663643.py:1: LangChainDeprecationWarning: The method `BaseRetriever.get_relevant_documents` was deprecated in langchain-core 0.1.46 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
            "  docs = retriever.get_relevant_documents(question)\n"
          ]
        }
      ],
      "source": [
        "docs = retriever.get_relevant_documents(question)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "3r6AeRp5ddtO"
      },
      "outputs": [],
      "source": [
        "for d in docs:\n",
        "    d.metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TjRj-23dzcX"
      },
      "source": [
        "## **Additional tricks: compression**\n",
        "\n",
        "Another approach for improving the quality of retrieved docs is compression.\n",
        "\n",
        "Information most relevant to a query may be buried in a document with a lot of irrelevant text.\n",
        "\n",
        "Passing that full document through your application can lead to more expensive LLM calls and poorer responses.\n",
        "\n",
        "Contextual compression is meant to fix this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "vdWqgzQUdgD2"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "-EeUfJS_d2Ok"
      },
      "outputs": [],
      "source": [
        "def pretty_print_docs(docs):\n",
        "    print(f\"\\n{'-' * 100}\\n\".join([f\"Document {i+1}:\\n\\n\" + d.page_content for i, d in enumerate(docs)]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1LIo3aO9d3T9"
      },
      "outputs": [],
      "source": [
        "# Wrap our vectorstore\n",
        "llm = BedrockLLM(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "compressor = LLMChainExtractor.from_llm(llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "4U8aNmNTd7MV"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever()\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyAK28F2d8ja",
        "outputId": "e5c9f3cc-8473-43f9-d151-4d823ff966a7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "The student said, \"Oh, it was the MATLAB.\"\n",
            "The friend asked, \"So what was it that you learned that was so helpful?\" And the student replied, \"Oh, it was the MATLAB.\"\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "The student said, \"Oh, it was the MATLAB.\"\n",
            "So for those of you that don't know MATLAB yet, I hope you do learn it. It's not hard, \n",
            "and we'll actually have a short MATLAB tutorial in one of the discussion sections for \n",
            "those of you that don't know it.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "MATLAB is a programming language that makes it easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. It's an extremely easy to learn tool to use for implementing a lot of learning algorithms. There's also a software package called Octave that you can download for free off the Internet. It has fewer features than MATLAB but it will work for the purposes of this class.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "those homeworks will be done in either MATLAB or in Octave, which is sort of — I know some people call it a free version of MATLAB, which it sort of is, sort of isn't.\n",
            "\n",
            "MATLAB is part of the programming language that makes it very easy to write codes using matrices, to write code for numerical routines, to move data around, to plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of learning algorithms.\n",
            "\n",
            "There's also a software package called Octave that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\n",
            "\n",
            "Once a colleague of mine at a different university, not at Stanford, actually teaches another machine learning course. He's taught it for many years. So one day, he was in his office, and an old student of his from, like, ten years ago came into his office and he said, \"Oh, professor, professor, thank you so much for your class. I'm working on this project now, and I couldn't have done it without MATLAB.\"\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsmkyBr6eBpd"
      },
      "source": [
        "# **Combining various techniques**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "9CDG99iTd9k7"
      },
      "outputs": [],
      "source": [
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever(search_type = \"mmr\")\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5n6DowTeFVs",
        "outputId": "7c157940-618c-4442-eef0-6499dc7c1428"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Document 1:\n",
            "\n",
            "The student said, \"Oh, it was the MATLAB.\"\n",
            "\n",
            "The context includes the student expressing gratitude for the machine learning class and mentioning that they learned something useful, which is MATLAB. The friend then asks which specific thing was learned, and the student responds with \"MATLAB\". There is no further discussion about MATLAB in the context. Therefore, the relevant part is the student's statement that \"it was the MATLAB\".\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 2:\n",
            "\n",
            "those homeworks will be done in either MATLAB or in Octave, which is sort of — I know some people call it a free version of MATLAB, which it sort of is, sort of isn't.\n",
            "\n",
            "So I guess for those of you that haven't seen MATLAB before, and I know most of you \n",
            "have, MATLAB is I guess part of the programming language that makes it very easy to \n",
            "write codes using matrices, to write code for numerical routines, to move data around, to \n",
            "plot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \n",
            "learning algorithms.\n",
            "\n",
            "There's also a software package called Octave that you can download for free off the Internet. And it has somewhat fewer features than MATLAB, but it's free, and for the purposes of this class, it will work for just about everything.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 3:\n",
            "\n",
            "I'll say a bit more about that later. I'll assume all of you know what random variables are, that all of you know what expectation is, what a variance or a random variable is. I also assume familiarity with basic probability and statistics. So most undergraduate statistics class, like Stat 116 taught here at Stanford, will be more than enough. I'm gonna assume all of you know what matrixes and vectors are, that you know how to multiply matrices and vectors and multiply matrix and matrices, that you know what a matrix inverse is. If you know what an eigenvector of a matrix is, that'd be even better. But if you don't quite know or if you're not quite sure, that's fine, too. We'll go over it in the review sections.\n",
            "\n",
            "I'll say a bit more about MATLAB or Octave later.\n",
            "\n",
            "Relevant output: I'll say a bit more about MATLAB or Octave later. The context indicates that programming in MATLAB or Octave will be a part of the class.\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Document 4:\n",
            "\n",
            "> It turns out if you do it in MATLAB, you can do it in one line of code.  \n",
            "> I'll also mention that it did take researchers many, many years to come up with that one line of code, so this is not easy. \n",
            "\n",
            "These parts of the context indicate that implementing a complicated algorithm in MATLAB can be done with relatively few lines of code compared to other programming languages like C or Java. It also mentions that it took researchers many years to develop the one-line code, indicating that while it may be possible to do it quickly in MATLAB, it is still a complex task.\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "compressed_docs = compression_retriever.get_relevant_documents(question)\n",
        "pretty_print_docs(compressed_docs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IyR-CLONeJ3J"
      },
      "source": [
        "# **Other types of retrieval**\n",
        "\n",
        "It's worth noting that vectordb as not the only kind of tool to retrieve documents.\n",
        "\n",
        "The `LangChain` retriever abstraction includes other ways to retrieve documents, such as TF-IDF or SVM."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "YGnmxnyDeGnR"
      },
      "outputs": [],
      "source": [
        "from langchain.retrievers import SVMRetriever\n",
        "from langchain.retrievers import TFIDFRetriever\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "RAAwmUazeMoN"
      },
      "outputs": [],
      "source": [
        "# Load PDF\n",
        "loader = PyPDFLoader(\"/content/content/MachineLearning-Lecture01.pdf\")\n",
        "pages = loader.load()\n",
        "all_page_text=[p.page_content for p in pages]\n",
        "joined_page_text=\" \".join(all_page_text)\n",
        "\n",
        "# Split\n",
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1500,chunk_overlap = 150)\n",
        "splits = text_splitter.split_text(joined_page_text)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "iT2vMH8peQrN"
      },
      "outputs": [],
      "source": [
        "# Retrieve\n",
        "svm_retriever = SVMRetriever.from_texts(splits,embedding)\n",
        "tfidf_retriever = TFIDFRetriever.from_texts(splits)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS386Lk6eSpN",
        "outputId": "611a1c14-6397-498d-82dc-975287e68e25"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"Testing, testing. Okay, cool. Thanks. So all right, online resources. The class has a home page, so it's in on the handouts. I \\nwon't write on the chalkboard — http:// cs229.stanford.edu. And so when there are \\nhomework assignments or things like that, we usually won't sort of — in the mission of \\nsaving trees, we will usually not give out many handouts in class. So homework \\nassignments, homework solutions will be posted online at the course home page.  \\nAs far as this class, I've also written, and I guess I've also revised every year a set of \\nfairly detailed lecture notes that cover the technical content of this class. And so if you \\nvisit the course homepage, you'll also find the detailed lecture notes that go over in detail \\nall the math and equations and so on that I'll be doing in class.  \\nThere's also a newsgroup, su.class.cs229, also written on the handout. This is a \\nnewsgroup that's sort of a forum for people in the class to get to know each other and \\nhave whatever discussions you want to have amongst yourselves. So the class newsgroup \\nwill not be monitored by the TAs and me. But this is a place for you to form study groups \\nor find project partners or discuss homework problems and so on, and it's not monitored \\nby the TAs and me. So feel free to talk trash about this class there.  \\nIf you want to contact the teaching staff, please use the email address written down here, \\ncs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So\")"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"What are major topics for this class?\"\n",
        "docs_svm=svm_retriever.get_relevant_documents(question)\n",
        "docs_svm[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BI9uxgteUZx",
        "outputId": "ddc21e95-a3f8-4b03-c781-788886485ea5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(metadata={}, page_content=\"yourselves. You can also come and talk to me or the TAs if you want to brainstorm ideas \\nwith us.  \\nOkay. So one more organizational question. I'm curious, how many of you know \\nMATLAB? Wow, cool, quite a lot. Okay. So as part of the — act ually how many of you \\nknow Octave or have used Octave? Oh, okay, much smaller number.  \\nSo as part of this class, especially in the homeworks, we'll ask you to implement a few \\nprograms, a few machine learning algorithms as part of the homeworks. And most of those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn't.  \\nSo I guess for those of you that haven't seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it's sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon't have a MATLAB license, for the purposes of this class, there's also — [inaudible] \\nwrite that down [inaudible] MATLAB — there' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it's free, and for the purposes of this class, it will work for just about \\neverything.\")"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "question = \"what did they say about matlab?\"\n",
        "docs_tfidf=tfidf_retriever.get_relevant_documents(question)\n",
        "docs_tfidf[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRmZkqrCe0hg"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "Explore different retrieval techniques in LangChain to fetch relevant documents based on queries.\n",
        "\n",
        "## **Scenario**\n",
        "\n",
        "You are building a document retrieval system for a research library. This activity will help you understand and implement various retrieval methods to efficiently fetch documents related to specific topics or queries.\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Load Documents\n",
        "* Embedding and Vector Store\n",
        "* Similarity Search\n",
        "* Maximum Marginal Relevance (MMR)\n",
        "* Metadata Filtering\n",
        "* Alternative Retrieval Methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDANj1w7eWUQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
