{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2sKJOkJ8ymIu"
      },
      "source": [
        "# **Schema**\n",
        "- Nuts and Bolts of working with Large Language Models (LLMs)\n",
        "\n",
        "**Problem Statement**\n",
        "- Design and implement a schema for interacting with Large Language Models (LLMs) that ensures consistent, structured, and efficient communication."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5KUU7dHAy40b"
      },
      "source": [
        "## **Text**\n",
        "- The natural language way to interact with LLMs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mFFpbfTezUXu"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain_aws"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "PN-Tn7S-zRtO"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from langchain_aws import ChatBedrock\n",
        "from google.colab import userdata\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = userdata.get('AWS_DEFAULT_REGION')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "CjJN2uNAy7zP",
        "outputId": "da075ed2-6716-4432-f88b-4d0b77f32ea8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'What day comes after Friday?'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# You'll be working with simple strings as prompts(that'll soon grow in complexity!)\n",
        "my_text = \"What day comes after Friday?\"\n",
        "my_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "ROZyFauUkh1U",
        "outputId": "ece40775-f3c9-4486-a05d-434a06eaa87f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The day that comes after Friday is Saturday. In a weekly cycle, Friday is followed by Saturday.'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from langchain.schema import HumanMessage\n",
        "chat = ChatBedrock(\n",
        "    model_id=\"mistral.mistral-7b-instruct-v0:2\",\n",
        "    temperature=0.7,\n",
        ")\n",
        "response = chat.invoke([HumanMessage(content=my_text)])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CAtXSeHiyysP"
      },
      "source": [
        "## **Chat Messages**\n",
        "Like text, but specified with a message type (System, Human, AI)\n",
        "\n",
        "* **System** - Helpful background context that tell the AI what to do\n",
        "* **Human** - Messages that are intented to represent the user\n",
        "* **AI** - Messages that show what the AI responded with"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qQMBQ1eOy1DR"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import HumanMessage, SystemMessage, AIMessage"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZMOJ-3U0y-Y"
      },
      "source": [
        "Now let's create a few messages that simulate a chat experience with a bot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNi-wrj0hsF",
        "outputId": "92e79e8e-4da0-4aea-c02d-ac5b4d91719a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " Consider trying a fresh tomato salad or a caprese bruschetta for a delicious and satisfying meal.\n"
          ]
        }
      ],
      "source": [
        "# Chat messages example\n",
        "response = chat([\n",
        "    SystemMessage(content=\"You are a nice AI bot that helps a user figure out what to eat in one short sentence\"),\n",
        "    HumanMessage(content=\"I like tomatoes, what should I eat?\")\n",
        "])\n",
        "print(response.content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0HZ6pJr51JVS"
      },
      "source": [
        "\n",
        "You can also pass more chat history w/ responses from the AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IG_MQHiz02Gf",
        "outputId": "5e3aa5c3-bfd9-4638-ebe0-73410c89336a"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nYou can also explore Old Town Nice, visit the famous Promenade des Anglais, and relax at Colline du Ch√¢teau for a beautiful view of the city and the sea. Enjoy your trip!'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat(\n",
        "    [\n",
        "        SystemMessage(content=\"You are a nice AI bot that helps a user figure out where to travel in one short sentence\"),\n",
        "        HumanMessage(content=\"I like the beaches where should I go?\"),\n",
        "        AIMessage(content=\"You should go to Nice, France\"),\n",
        "        HumanMessage(content=\"What else should I do when I'm there?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfkytXMI1M4A"
      },
      "source": [
        "You can also exclude the system message if you want"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "xNJqFOUo1LbX",
        "outputId": "4a48adba-5db5-406b-ac12-80d2707f6143"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The day that comes after Thursday is Friday. In a seven-day cycle, Thursday is followed by Friday. This sequence holds true in all calendar systems, including the Gregorian calendar, which is the most widely used calendar system in the world today.'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response = chat(\n",
        "    [\n",
        "        HumanMessage(content=\"What day comes after Thursday?\")\n",
        "    ]\n",
        ")\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TjWPkWmQ1Wt8"
      },
      "source": [
        "## **Documents**\n",
        "An object that holds a piece of text and metadata (more information about that text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "toEl31Pa1QO2"
      },
      "outputs": [],
      "source": [
        "from langchain.schema import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "qcwHNuao1aZW"
      },
      "outputs": [],
      "source": [
        "document = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\",\n",
        "         metadata={\n",
        "             'my_document_id' : 234234,\n",
        "             'my_document_source' : \"The LangChain Papers\",\n",
        "             'my_document_create_time' : 1680013019\n",
        "         })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "Z-0Gd4KXoUz3"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt = f\"Document Content: {document.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "1vTNnNX3oZjm",
        "outputId": "5016c61c-c395-4f24-d4d5-bf4ad8429559"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The document is a personal document labeled as \"my document.\" It contains text that the owner has collected from various sources. There is no specific information or content provided in the document for summary.'"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke([HumanMessage(content=f\"Summarize the following document:\\n\\n{prompt}\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dGXfmlSV1irM"
      },
      "source": [
        "But you don't have to include metadata if you don't want to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "WLVasVVM1ceF"
      },
      "outputs": [],
      "source": [
        "document1 = Document(page_content=\"This is my document. It is full of text that I've gathered from other places\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "8nRGsnjmos-1"
      },
      "outputs": [],
      "source": [
        "# Prepare the prompt by combining the document content with your custom prompt\n",
        "prompt1 = f\"Document Content: {document1.page_content}\\n\\nPlease summarize the above document.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "id": "i_4SDqdso1Be",
        "outputId": "da9d704d-c13c-4125-be44-66574a2dfba5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' The document is a personal one, titled \"my document.\" Its content consists of text that the document owner has collected from various sources. There is no specific information or topic discussed in the document.'"
            ]
          },
          "execution_count": 32,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Get the response from the language model\n",
        "response = chat.invoke([HumanMessage(content=f\"Summarize the following document:\\n\\n{prompt1}\")])\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yt9P_Vs8VSE-"
      },
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "Create a simple interaction using LangChain and AWS. Define system, human, and AI messages to simulate a conversation with a travel recommendation bot. Additionally, create a document schema to store information about travel destinations.\n",
        "\n",
        "**Steps**\n",
        "\n",
        "* **Set Up**: Install the necessary libraries and set up your AWS Secret Key and Access Key.\n",
        "* **Define Messages**: Create system, human, and AI messages for a travel bot.\n",
        "* **Simulate Interaction**: Use the chat function to simulate a conversation.\n",
        "* **`Create Document`**: Define a document schema to store information about a travel destination."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNykOX6_VSaz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
