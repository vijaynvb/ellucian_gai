{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **VectorStore and Embeddings**\n",
        "\n",
        "We need vector stores and embeddings to efficiently handle and retrieve relevant information from large text datasets. Embeddings convert text data into numerical vectors that capture semantic meaning, enabling more accurate search and retrieval by understanding context and similarity. Vector stores index these embeddings, allowing for quick and scalable similarity searches, essential for applications like recommendation systems, information retrieval, and natural language processing tasks. Combining both ensures high performance in accessing and utilizing vast amounts of text data."
      ],
      "metadata": {
        "id": "dQj_xgvpT9uy"
      },
      "id": "dQj_xgvpT9uy"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c81a13b1",
      "metadata": {
        "id": "c81a13b1"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# update or install the necessary libraries\n",
        "!pip install --upgrade langchain langchain_community langchain_aws pypdf tiktoken chromadb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "os.environ[\"AWS_ACCESS_KEY_ID\"] = userdata.get('AWS_ACCESS_KEY_ID')\n",
        "os.environ[\"AWS_SECRET_ACCESS_KEY\"] = userdata.get('AWS_SECRET_ACCESS_KEY')\n",
        "os.environ[\"AWS_DEFAULT_REGION\"] = userdata.get('AWS_DEFAULT_REGION')"
      ],
      "metadata": {
        "id": "uhrSlEaBzNoZ"
      },
      "id": "uhrSlEaBzNoZ",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We just discussed `Document Loading` and `Splitting`.\n"
      ],
      "metadata": {
        "id": "IirOq9leTbm5"
      },
      "id": "IirOq9leTbm5"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "ce244283",
      "metadata": {
        "id": "ce244283"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "# Load PDF\n",
        "loaders = [\n",
        "    # Duplicate documents on purpose - messy data\n",
        "    PyPDFLoader(\"/content/content/MachineLearning-Lecture01.pdf\"),\n",
        "    PyPDFLoader(\"/content/content/MachineLearning-Lecture02.pdf\"),\n",
        "    PyPDFLoader(\"/content/content/MachineLearning-Lecture03.pdf\")\n",
        "\n",
        "]\n",
        "docs = []\n",
        "for loader in loaders:\n",
        "    docs.extend(loader.load())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f52d2eec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f52d2eec",
        "outputId": "16d7480c-fbc6-4c38-82b3-ec565997c501"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "151"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Split\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1500,\n",
        "    chunk_overlap = 150\n",
        ")\n",
        "\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "len(splits)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Embeddings**\n",
        "\n",
        "Embedding is a technique that transforms text or other data into numerical vectors, capturing semantic relationships and contextual meaning. These vectors enable machines to process and analyze the data more effectively, facilitating tasks such as search, recommendation, and natural language understanding.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "Let's take our splits and embed them."
      ],
      "metadata": {
        "id": "xUR4SEbtTloz"
      },
      "id": "xUR4SEbtTloz"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "87dac68a",
      "metadata": {
        "id": "87dac68a"
      },
      "outputs": [],
      "source": [
        "# Embeddings\n",
        "\n",
        "from langchain_aws import BedrockEmbeddings\n",
        "\n",
        "embedding = BedrockEmbeddings(\n",
        "    model_id=\"amazon.titan-embed-text-v2:0\"\n",
        ")\n",
        "\n",
        "sentence1 = \"i like Workplace conditions\"\n",
        "sentence2 = \"i like Employees  Efficiency and Effectiveness\"\n",
        "sentence3 = \" Employee’s Characteristics and Creativity\"\n",
        "\n",
        "embedding1 = embedding.embed_query(sentence1)\n",
        "embedding2 = embedding.embed_query(sentence2)\n",
        "embedding3 = embedding.embed_query(sentence3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "f3875c82",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3875c82",
        "outputId": "a24a17ac-f809-4258-a6ba-d2d9bca757c2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "np.float64(0.22245856395925306)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "np.dot(embedding1, embedding3)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Vectorstores**\n",
        "\n",
        "A vector store is a database designed to store and manage numerical vectors, such as embeddings, for efficient retrieval and similarity search. It enables quick and accurate matching of vectors, facilitating tasks like nearest neighbor search, clustering, and recommendation systems based on vector similarity."
      ],
      "metadata": {
        "id": "yzgjhoeSTr9T"
      },
      "id": "yzgjhoeSTr9T"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6a979239",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6a979239",
        "outputId": "be1c8d06-675d-492f-eae9-a3aedb5f52d1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "151\n"
          ]
        }
      ],
      "source": [
        "from langchain.vectorstores import Chroma\n",
        "persist_directory = 'docs/chroma/'\n",
        "# !rm -rf ./docs/chroma  # remove old database files if any\n",
        "vectordb = Chroma.from_documents(\n",
        "    documents=splits,\n",
        "    embedding=embedding,\n",
        "    persist_directory=persist_directory\n",
        ")\n",
        "\n",
        "print(vectordb._collection.count())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"is there an email i can ask for help\""
      ],
      "metadata": {
        "id": "2hpDRTy06N2o"
      },
      "id": "2hpDRTy06N2o",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vectordb.similarity_search(question,k=3)"
      ],
      "metadata": {
        "id": "HPx0V_iQ6SCC"
      },
      "id": "HPx0V_iQ6SCC",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0].page_content"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "qSIyTmv96XYS",
        "outputId": "27db4309-c433-4322-8bf8-e64b1613a0c4"
      },
      "id": "qSIyTmv96XYS",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"cs229-qa@cs.stanford.edu. This goes to an account that's read by all the TAs and me. So \\nrather than sending us email individually, if you send email to this account, it will \\nactually let us get back to you maximally quickly with answers to your questions.  \\nIf you're asking questions about homework problems, please say in the subject line which \\nassignment and which question the email refers to, since that will also help us to route \\nyour question to the appropriate TA or to me appropriately and get the response back to \\nyou quickly.  \\nLet's see. Skipping ahead — let's see — for homework, one midterm, one open and term \\nproject. Notice on the honor code. So one thing that I think will help you to succeed and \\ndo well in this class and even help you to enjoy this class more is if you form a study \\ngroup.  \\nSo start looking around where you're sitting now or at the end of class today, mingle a \\nlittle bit and get to know your classmates. I strongly encourage you to form study groups \\nand sort of have a group of people to study with and have a group of your fellow students \\nto talk over these concepts with. You can also post on the class newsgroup if you want to \\nuse that to try to form a study group.  \\nBut some of the problems sets in this class are reasonably difficult. People that have \\ntaken the class before may tell you they were very difficult. And just I bet it would be \\nmore fun for you, and you'd probably have a better learning experience if you form a\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's save this so we can use it later!\n",
        "vectordb.persist()"
      ],
      "metadata": {
        "id": "o-UzxXZw7l1h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb10ebb8-402a-4185-d5d4-21382d074dd9"
      },
      "id": "o-UzxXZw7l1h",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-12-891976456.py:2: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
            "  vectordb.persist()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Failure modes\n",
        "\n",
        "This seems great, and basic similarity search will get you 80% of the way there very easily.\n",
        "\n",
        "But there are some failure modes that can creep up.\n",
        "\n",
        "Here are some edge cases that can arise - we'll fix them in the next class."
      ],
      "metadata": {
        "id": "92J_MgV-S0BQ"
      },
      "id": "92J_MgV-S0BQ"
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"what did they say about matlab?\""
      ],
      "metadata": {
        "id": "F4kwHuw87uja"
      },
      "id": "F4kwHuw87uja",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs = vectordb.similarity_search(question,k=5)"
      ],
      "metadata": {
        "id": "d7qW3nwG72U5"
      },
      "id": "d7qW3nwG72U5",
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice that we're getting duplicate chunks (because of the duplicate MachineLearning-Lecture01.pdf in the index).\n",
        "\n",
        "Semantic search fetches all similar documents, but does not enforce diversity.\n",
        "\n",
        "docs[0] and docs[1] are indentical."
      ],
      "metadata": {
        "id": "esPJir0ZTGCG"
      },
      "id": "esPJir0ZTGCG"
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BvSR7__FTF-k"
      },
      "id": "BvSR7__FTF-k"
    },
    {
      "cell_type": "code",
      "source": [
        "docs[0]"
      ],
      "metadata": {
        "id": "SVQInNyGS-mn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e8f7f7c-93c0-4736-c8a9-9d6be2e9374a"
      },
      "id": "SVQInNyGS-mn",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'total_pages': 22, 'title': '', 'creationdate': '2008-07-11T11:25:23-07:00', 'moddate': '2008-07-11T11:25:23-07:00', 'author': '', 'source': '/content/content/MachineLearning-Lecture01.pdf', 'page_label': '9', 'page': 8, 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)'}, page_content='into his office and he said, \"Oh, professor, professor, thank you so much for your \\nmachine learning class. I learned so much from it. There\\'s this stuff that I learned in your \\nclass, and I now use every day. And it\\'s helped me make lots of money, and here\\'s a \\npicture of my big house.\"  \\nSo my friend was very excited. He said, \"Wow. That\\'s great. I\\'m glad to hear this \\nmachine learning stuff was actually useful. So what was it that you learned? Was it \\nlogistic regression? Was it the PCA? Was it the data networks? What was it that you \\nlearned that was so helpful?\" And the student said, \"Oh, it was the MATLAB.\"  \\nSo for those of you that don\\'t know MATLAB yet, I hope you do learn it. It\\'s not hard, \\nand we\\'ll actually have a short MATLAB tutorial in one of the discussion sections for \\nthose of you that don\\'t know it.  \\nOkay. The very last piece of logistical thing is the discussion sections. So discussion \\nsections will be taught by the TAs, and attendance at discussion sections is optional, \\nalthough they\\'ll also be recorded and televised. And we\\'ll use the discussion sections \\nmainly for two things. For the next two or three weeks, we\\'ll use the discussion sections \\nto go over the prerequisites to this class or if some of you haven\\'t seen probability or \\nstatistics for a while or maybe algebra, we\\'ll go over those in the discussion sections as a \\nrefresher for those of you that want one.')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[1]"
      ],
      "metadata": {
        "id": "nwUldKazTBI6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d5dbe51-2644-45d8-f695-8ef986fa42c3"
      },
      "id": "nwUldKazTBI6",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(metadata={'page': 8, 'creator': 'PScript5.dll Version 5.2.2', 'total_pages': 22, 'author': '', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'moddate': '2008-07-11T11:25:23-07:00', 'page_label': '9', 'creationdate': '2008-07-11T11:25:23-07:00', 'title': '', 'source': '/content/content/MachineLearning-Lecture01.pdf'}, page_content='those homeworks will be done in either MATLAB or in Octave, which is sort of — I \\nknow some people call it a free version of MATLAB, which it sort of is, sort of isn\\'t.  \\nSo I guess for those of you that haven\\'t seen MATLAB before, and I know most of you \\nhave, MATLAB is I guess part of the programming language that makes it very easy to \\nwrite codes using matrices, to write code for numerical routines, to move data around, to \\nplot data. And it\\'s sort of an extremely easy to learn tool to use for implementing a lot of \\nlearning algorithms.  \\nAnd in case some of you want to work on your own home computer or something if you \\ndon\\'t have a MATLAB license, for the purposes of this class, there\\'s also — [inaudible] \\nwrite that down [inaudible] MATLAB — there\\' s also a software package called Octave \\nthat you can download for free off the Internet. And it has somewhat fewer features than \\nMATLAB, but it\\'s free, and for the purposes of this class, it will work for just about \\neverything.  \\nSo actually I, well, so yeah, just a side comment for those of you that haven\\'t seen \\nMATLAB before I guess, once a colleague of mine at a different university, not at \\nStanford, actually teaches another machine learning course. He\\'s taught it for many years. \\nSo one day, he was in his office, and an old student of his from, like, ten years ago came \\ninto his office and he said, \"Oh, professor, professor, thank you so much for your')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see a new failure mode.\n",
        "\n",
        "The question below asks a question about the third lecture, but includes results from other lectures as well."
      ],
      "metadata": {
        "id": "z9lGpbaBTM5A"
      },
      "id": "z9lGpbaBTM5A"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "9ba1fa29",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ba1fa29",
        "outputId": "e6f90e17-3cf9-4988-f3a3-615a88042e35"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'author': '', 'creator': 'PScript5.dll Version 5.2.2', 'title': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'source': '/content/content/MachineLearning-Lecture03.pdf', 'page_label': '1', 'page': 0, 'moddate': '2008-07-11T11:25:03-07:00', 'total_pages': 16}\n",
            "{'title': '', 'moddate': '2008-07-11T11:25:05-07:00', 'source': '/content/content/MachineLearning-Lecture02.pdf', 'creationdate': '2008-07-11T11:25:05-07:00', 'author': '', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'total_pages': 18, 'page': 0, 'page_label': '1', 'creator': 'PScript5.dll Version 5.2.2'}\n",
            "{'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page_label': '4', 'creationdate': '2008-07-11T11:25:03-07:00', 'creator': 'PScript5.dll Version 5.2.2', 'title': '', 'source': '/content/content/MachineLearning-Lecture03.pdf', 'page': 3, 'moddate': '2008-07-11T11:25:03-07:00', 'total_pages': 16, 'author': ''}\n",
            "{'creationdate': '2008-07-11T11:25:03-07:00', 'page_label': '7', 'total_pages': 16, 'title': '', 'page': 6, 'author': '', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'moddate': '2008-07-11T11:25:03-07:00', 'source': '/content/content/MachineLearning-Lecture03.pdf', 'creator': 'PScript5.dll Version 5.2.2'}\n",
            "{'title': '', 'source': '/content/content/MachineLearning-Lecture03.pdf', 'total_pages': 16, 'creator': 'PScript5.dll Version 5.2.2', 'producer': 'Acrobat Distiller 8.1.0 (Windows)', 'page': 13, 'page_label': '14', 'author': '', 'creationdate': '2008-07-11T11:25:03-07:00', 'moddate': '2008-07-11T11:25:03-07:00'}\n",
            "least squares regression being a bad idea for classification problems and then I did a \n",
            "bunch of math and I skipped some steps, but I’m, sort of, claiming at the end they’re \n",
            "really the same learning algorithm?  \n",
            "Student:[Inaudible] constants?  \n",
            "Instructor (Andrew Ng):Say that again.  \n",
            "Student:[Inaudible]  \n",
            "Instructor (Andrew Ng):Oh, right. Okay, cool.\n"
          ]
        }
      ],
      "source": [
        "question = \"what did they say about regression in the third lecture?\"\n",
        "docs = vectordb.similarity_search(question,k=5)\n",
        "for doc in docs:\n",
        "    print(doc.metadata)\n",
        "print(docs[4].page_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Let's Do an Activity**\n",
        "\n",
        "## **Objective**\n",
        "\n",
        "In this activity, you will learn to use embeddings and vector stores to perform efficient similarity searches and data retrieval. You will practice creating embeddings from text data, storing them in a vector store, and retrieving relevant information based on similarity queries.\n",
        "\n",
        "## **Scenario**\n",
        "\n",
        "You are building a recommendation system that suggests documents based on user queries. To achieve this, you will use LangChain to create embeddings from text data and store these embeddings in a vector store. You will then use the vector store to find the most relevant documents for a given query.\n",
        "\n",
        "## **Steps**\n",
        "\n",
        "* Load and Split Documents\n",
        "* Create Embeddings\n",
        "* Store Embeddings in Vector Store\n",
        "* Perform Similarity Search"
      ],
      "metadata": {
        "id": "ua5k5b2oWe-o"
      },
      "id": "ua5k5b2oWe-o"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WZMHfzB6SRrr"
      },
      "id": "WZMHfzB6SRrr",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}